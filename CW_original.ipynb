{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from clockwork_helperfunc import *\n",
    "from clockwork_helperfunc import evaluation\n",
    "import clockwork_helperfunc \n",
    "from imp import reload  \n",
    "reload(clockwork_helperfunc)\n",
    "\n",
    "#configuration\n",
    "batch_size = 5\n",
    "num_epochs = 50\n",
    "number_units = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "training = pd.read_pickle('/Users/leilei/Documents/DS1005/CW/truncate_train_data.p')\n",
    "val = pd.read_pickle('/Users/leilei/Documents/DS1005/CW/truncate_valid_data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "patient_feature_train, label_train, label_time_train = downsample(training, proportional = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "patient_feature_val = val[0] #before cleaning, original data\n",
    "label_val = val[1]\n",
    "label_time_val = val[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521392, 237789)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(label_time_train), sum(label_train*label_time_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 3535, 1: 1765}), Counter({0: 4051, 1: 549}))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_train), Counter(label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5300"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patient_feature_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### small_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, len(patient_feature_train),10)\n",
    "patient_feature_train_sub, label_train_sub, label_time_train_sub = patient_feature_train.copy(), label_train.copy(), label_time_train.copy()\n",
    "patient_feature_train, label_train, label_time_train = patient_feature_train_sub[idx], label_train_sub[idx], label_time_train_sub[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#patient_feature_train = [patient_feature_train[i][:i+1, :5] for i in range(len(patient_feature_train))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Model\n",
    "#forward\n",
    "#cell_class, step\n",
    "class Clock_NN(nn.Module):\n",
    "    def __init__(self, scale,batch_size, group_size = 1, activation_fun =nn.Tanh, mean = 0, std = 1, input_dim = 48,mode = 'shift'):\n",
    "        super(Clock_NN, self).__init__()\n",
    "        '''\n",
    "        scale: the updating frequency, a list. [1,2,4,8,16,32]\n",
    "        batch_size: the size of batch\n",
    "        group_size: the number of nodes in each scale, default is 1.\n",
    "        activation_function\n",
    "        mean: the mean of Gaussian distribution for initialize weights for hidden layer\n",
    "        std: the standard devation of the Gaussian distribution for initialize weights for hidden layer\n",
    "        input_dim: the feature dimension of each time step\n",
    "        '''\n",
    "        self.scale = scale\n",
    "        self.group_size = group_size\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        if mode == 'original':\n",
    "            self.num_units = len(self.scale)*self.group_size\n",
    "            self.index_li = {self.scale[i]: i for i in range(len(self.scale))}\n",
    "        elif mode == 'shift':\n",
    "            self.num_units = sum(self.scale)*self.group_size\n",
    "            self.index_li = {i:i-1 for i in self.scale}\n",
    "            \n",
    "        self.class_dim = 2\n",
    "        self.input_dim = input_dim\n",
    "        self.linear_h = nn.Linear(self.num_units,self.num_units)\n",
    "        self.linear_o = nn.Linear(self.num_units,self.class_dim)\n",
    "        self.linear_i = nn.Linear(self.input_dim, self.num_units)\n",
    "        self.activation_fun = activation_fun\n",
    "        self.connect = torch.from_numpy(block_tri(self.group_size, self.scale, self.num_units, self.mode)).float()\n",
    "        self.time_step = 0\n",
    "        \n",
    "        self.initial_weights(mean, std)\n",
    "        \n",
    "        #the connectivity, when we disabled the weight, this should not change\n",
    "        self.linear_h.weight.data = self.linear_h.weight.data*self.connect#here needs transpose since previously left multiplication, activate mtrx doesn't need as rewrite and select cols.\n",
    "        #self.linear_i.weight.data = self.linear_i.weight.data\n",
    "        \n",
    "    def forward(self, sequence, hidden):#depends on what passed for model.train(), to be filled)\n",
    "        '''\n",
    "        sequence: batch  x timestep x number_feature matrix\n",
    "        hidden: should be h0\n",
    "        '''     \n",
    "        #sequence = sequence.view(48,-1)when this is only one batch\n",
    "        hidden_output = []\n",
    "        length = sequence.size()[1]\n",
    "        logit = []\n",
    "        for i in range(length):\n",
    "            #print('this is the timestep ' + str(self.time_step))\n",
    "            self.time_step += 1\n",
    "            #backwards, want discharge/dead time aligns\n",
    "            #print(sequence[:,:,-i].size())#would be batch*48\n",
    "            hidden = self.CW_RNN_Cell(sequence[:,i,:].contiguous(), hidden)\n",
    "            hidden_output.append(hidden)#become batch_size x hidden_dim\n",
    "            out = self.linear_o(hidden)\n",
    "            logit.append(F.log_softmax(out))\n",
    "        return hidden_output, logit \n",
    "    #a list of predictions of each step(till the largest, each one is batch * hidden_dim); \n",
    "    #hidden_output is a list of output prediction, each one is batch * two\n",
    "            \n",
    "                \n",
    "    def CW_RNN_Cell(self, x_input, hidden):\n",
    "        '''\n",
    "        x_input: number_feature x batch vector, representing one time stamp\n",
    "        hidden: output of the last cell, should be hidden_dim(i.e. num_units) x batch\n",
    "        '''\n",
    "        #which time bloack to change\n",
    "        activate = activate_index(self.time_step, self.num_units, self.group_size, self.scale,self.index_li,batch_size,self.mode, self.input_dim)\n",
    "        activate_re = torch.from_numpy(np.ones((self.batch_size,self.num_units))).float() - activate\n",
    "\n",
    "        hidden_next = self.linear_h(hidden) + self.linear_i(x_input) #should be batch_size x hidden_dim       \n",
    "        hidden_next.data = activate*hidden_next.data + activate_re*hidden.data\n",
    "        hidden_next = self.activation_fun(hidden_next)\n",
    "        return hidden_next\n",
    "\n",
    "    def init_hidden(self):\n",
    "        h0 = Variable(torch.zeros(self.batch_size,self.num_units))\n",
    "        return h0\n",
    "        \n",
    "    def initial_weights(self, mean, std):\n",
    "        lin_layers = [self.linear_h, self.linear_o, self.linear_i]\n",
    "        for layer in lin_layers:\n",
    "            layer.weight.data.normal_(mean, std**2)\n",
    "            layer.bias.data.fill_(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Loss: 0.6930732131004333\n",
      "accuracy_on_validation: 0.6002173913043478, the acc for LIVE is 0.6184886280264124, the acc for DEAD is 0.45401174168297453\n",
      "the auc is 0.536250184855\n",
      "Epoch: 0; Loss: 0.692920446395874\n",
      "accuracy_on_validation: 0.6021739130434782, the acc for LIVE is 0.6187331865981903, the acc for DEAD is 0.46966731898238745\n",
      "the auc is 0.54420025279\n",
      "Epoch: 0; Loss: 0.6928211450576782\n",
      "accuracy_on_validation: 0.6086956521739131, the acc for LIVE is 0.6292492051846417, the acc for DEAD is 0.44422700587084146\n",
      "the auc is 0.536738105528\n",
      "Epoch: 0; Loss: 0.6931390762329102\n",
      "accuracy_on_validation: 0.6121739130434782, the acc for LIVE is 0.6336512594766447, the acc for DEAD is 0.44031311154598823\n",
      "the auc is 0.536982185511\n",
      "Epoch: 0; Loss: 0.6928198337554932\n",
      "accuracy_on_validation: 0.6, the acc for LIVE is 0.6184886280264124, the acc for DEAD is 0.4520547945205479\n",
      "the auc is 0.535271711273\n",
      "Epoch: 0; Loss: 0.6931297779083252\n",
      "accuracy_on_validation: 0.6060869565217392, the acc for LIVE is 0.6272927366104182, the acc for DEAD is 0.436399217221135\n",
      "the auc is 0.531845976916\n",
      "Epoch: 0; Loss: 0.6932047605514526\n",
      "accuracy_on_validation: 0.6178260869565217, the acc for LIVE is 0.6351186109073123, the acc for DEAD is 0.4794520547945205\n",
      "the auc is 0.557285332851\n",
      "Epoch: 0; Loss: 0.6932396292686462\n",
      "accuracy_on_validation: 0.6215217391304347, the acc for LIVE is 0.640743458058205, the acc for DEAD is 0.46771037181996084\n",
      "the auc is 0.554226914939\n",
      "Epoch: 0; Loss: 0.6931828260421753\n",
      "accuracy_on_validation: 0.6176086956521739, the acc for LIVE is 0.6368305209097579, the acc for DEAD is 0.4637964774951076\n",
      "the auc is 0.550313499202\n",
      "Epoch: 0; Loss: 0.6930570006370544\n",
      "accuracy_on_validation: 0.6134782608695653, the acc for LIVE is 0.6358522866226461, the acc for DEAD is 0.4344422700587084\n",
      "the auc is 0.535147278341\n",
      "Epoch: 0; Loss: 0.6929493546485901\n",
      "accuracy_on_validation: 0.621304347826087, the acc for LIVE is 0.6436781609195402, the acc for DEAD is 0.44227005870841485\n",
      "the auc is 0.542974109814\n",
      "Epoch: 0; Loss: 0.6926892399787903\n",
      "accuracy_on_validation: 0.6258695652173913, the acc for LIVE is 0.6478356566397653, the acc for DEAD is 0.4500978473581213\n",
      "the auc is 0.548966751999\n",
      "Epoch: 0; Loss: 0.6931224465370178\n",
      "accuracy_on_validation: 0.6265217391304347, the acc for LIVE is 0.648813890926877, the acc for DEAD is 0.4481409001956947\n",
      "the auc is 0.548477395561\n",
      "Epoch: 0; Loss: 0.6931352019309998\n",
      "accuracy_on_validation: 0.6321739130434783, the acc for LIVE is 0.6568843237955491, the acc for DEAD is 0.4344422700587084\n",
      "the auc is 0.545663296927\n",
      "Epoch: 0; Loss: 0.6930099725723267\n",
      "accuracy_on_validation: 0.6241304347826087, the acc for LIVE is 0.6485693323550991, the acc for DEAD is 0.42857142857142855\n",
      "the auc is 0.538570380463\n",
      "Epoch: 0; Loss: 0.6933329701423645\n",
      "accuracy_on_validation: 0.635, the acc for LIVE is 0.6585962337979946, the acc for DEAD is 0.4461839530332681\n",
      "the auc is 0.552390093416\n",
      "Epoch: 0; Loss: 0.6930666565895081\n",
      "accuracy_on_validation: 0.6397826086956522, the acc for LIVE is 0.6674003423820005, the acc for DEAD is 0.4187866927592955\n",
      "the auc is 0.543093517571\n",
      "Epoch: 0; Loss: 0.6932714581489563\n",
      "accuracy_on_validation: 0.6317391304347826, the acc for LIVE is 0.6578625580826608, the acc for DEAD is 0.4227005870841487\n",
      "the auc is 0.540281572583\n",
      "Epoch: 0; Loss: 0.6931666731834412\n",
      "accuracy_on_validation: 0.6432608695652174, the acc for LIVE is 0.6710687209586697, the acc for DEAD is 0.4207436399217221\n",
      "the auc is 0.54590618044\n",
      "Epoch: 0; Loss: 0.6934691667556763\n",
      "accuracy_on_validation: 0.65, the acc for LIVE is 0.6808510638297872, the acc for DEAD is 0.40313111545988256\n",
      "the auc is 0.541991089645\n",
      "Epoch: 0; Loss: 0.6930115818977356\n"
     ]
    }
   ],
   "source": [
    "### Training original\n",
    "model = Clock_NN([1,2,4,8,16], batch_size, group_size = 5, activation_fun = F.tanh, mean = 0, std = 0.1, input_dim = 40, mode = 'original')\n",
    "\n",
    "loss = torch.nn.NLLLoss(ignore_index=-1)  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000005)\n",
    "accuracy_list = []\n",
    "train_loader, validation_loader = reload_data(batch_size,patient_feature_train, label_train, label_time_train,patient_feature_val, label_val, label_time_val)\n",
    "for epoch in range(20):\n",
    "    for step, (data, label, label_time) in enumerate(train_loader):\n",
    "        data, label = Variable(data), Variable(label)\n",
    "        model.zero_grad()\n",
    "        hidden= model.init_hidden()\n",
    "        model.time_step = 0\n",
    "        hidden, output = model(data, hidden)\n",
    "        #print(hidden[0].size())\n",
    "        #print(output[0].size())\n",
    "        #now get a list of hidden and a list of outputs\n",
    "        \n",
    "        #patient level\n",
    "        label = label.transpose(0,1).contiguous().view(-1) \n",
    "        #should be flatten, batch_size x hidden. transpose due to below order, was batch, seq => follow up 2 down. get size batch*seq          \n",
    "        output = torch.stack(output, dim=1).view(-1, 2) \n",
    "        #print(output[-1])\n",
    "            \n",
    "        lossy = loss(output, label)\n",
    "        lossy.backward()\n",
    "        model.linear_h.weight.grad.data = model.linear_h.weight.grad.data*model.connect\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step%4 ==0 :\n",
    "            print(\"Epoch: {}; Loss: {}\".format(epoch, lossy.data[0]))\n",
    "            acc0, acc1, val_acc, auc = evaluation(validation_loader, model)\n",
    "            print('accuracy_on_validation: {}, the acc for LIVE is {}, the acc for DEAD is {}'.format(val_acc, acc0, acc1)) \n",
    "            print('the auc is ' + str(auc))\n",
    "    #accuracy_list.append(val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(data_loader, model, mode = 'novel'):\n",
    "    '''\n",
    "    This is the evaluation of patient level prediction.\n",
    "    '''\n",
    "    label_list = []\n",
    "    output_list = []\n",
    "    model.eval()\n",
    "    \n",
    "    for i, (data, label, time_list) in enumerate(data_loader):\n",
    "        data = Variable(data)\n",
    "        hidden= model.init_hidden()\n",
    "        #print(data.size()) #[5, 75, 48]\n",
    "        #print(time_list) #which is a list\n",
    "        if mode == 'novel':\n",
    "            hidden, ori_output = model(data, hidden)\n",
    "            ##print('the hidden size is ')\n",
    "            #print(hidden[0].data.size()) #batch_size * hidden dimension\n",
    "            #output is a list of prediction, everyone is batch * two\n",
    "            #print('output length' + str(len(output)))\n",
    "            #print('output single element size' + str(output[0].size()))\n",
    "            output = [np.argmax(ori_output[time_list[i] - 1][i].data.numpy()) for i in range(data.size()[0])]\n",
    "            #batch size, each one pick the element\n",
    "            #each prediction for each batch member\n",
    "            #print(output[0]) \n",
    "        else:\n",
    "            output = model(data, hidden).data.numpy() #should be [torch.FloatTensor of size batch * 1 * 3]\n",
    "        #now get a list of hidden and a list of outputs\n",
    "        #print(output)\n",
    "        label = label[:,0].numpy()\n",
    "        #print(label == output)\n",
    "        #label = label.transpose(0,1).contiguous().view(-1).data.numpy()\n",
    "\n",
    "        label_list.extend(label)\n",
    "        output_list.extend(output)\n",
    "    \n",
    "    label_list = np.array(label_list)\n",
    "    output_list = np.array(output_list)\n",
    "    \n",
    "    one_idx = np.where(label_list == 1)[0]\n",
    "    zero_idx = np.where(label_list == 0)[0]\n",
    "    \n",
    "    label_ones = label_list[one_idx] #both are array, can select index like this\n",
    "    label_zeros = label_list[zero_idx]\n",
    "    pre_ones = output_list[one_idx]#now softmax, turn into class\n",
    "    pre_zeros = output_list[zero_idx]\n",
    "        \n",
    "\n",
    "    acc0 = sum(pre_zeros == label_zeros)/len(pre_zeros)\n",
    "    acc1 = sum(pre_ones ==label_ones)/len(pre_ones)\n",
    "    acc =  (sum(pre_ones == label_ones) + sum(pre_zeros == label_zeros))/(len(pre_ones) + len(pre_zeros))\n",
    "    #print(type(label_ones), type(label_zeros), type(pre_ones),type(pre_zeros))\n",
    "    auc = roc_auc_score(list(label_ones) + list(label_zeros), list(pre_ones) + list(pre_zeros))\n",
    "    model.train()\n",
    "    return acc0, acc1,acc,auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3,4])[np.array([1,2,3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2dfd5cab2669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'novel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-7bc4cbb9ad5d>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(data_loader, model, mode)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#print(time_list) #which is a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'novel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mori_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;31m##print('the hidden size is ')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m#print(hidden[0].data.size()) #batch_size * hidden dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-9b0bb33028e4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sequence, hidden)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCW_RNN_Cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mhidden_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#become batch_size x hidden_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36maddmm\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAddmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_matrix_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         return torch.addmm(alpha, add_matrix, beta,\n\u001b[1;32m     26\u001b[0m                            matrix1, matrix2, out=output)\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36m_get_output\u001b[0;34m(ctx, arg, inplace)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluation(validation_loader, model, mode = 'novel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Model\n",
    "#forward\n",
    "#cell_class, step\n",
    "class Clock_NN(nn.Module):\n",
    "    def __init__(self, scale,batch_size, group_size = 1, activation_fun =nn.Tanh, mean = 0, std = 1, input_dim = 48,mode = 'shift'):\n",
    "        super(Clock_NN, self).__init__()\n",
    "        '''\n",
    "        scale: the updating frequency, a list. [1,2,4,8,16,32]\n",
    "        batch_size: the size of batch\n",
    "        group_size: the number of nodes in each scale, default is 1.\n",
    "        activation_function\n",
    "        mean: the mean of Gaussian distribution for initialize weights for hidden layer\n",
    "        std: the standard devation of the Gaussian distribution for initialize weights for hidden layer\n",
    "        input_dim: the feature dimension of each time step\n",
    "        '''\n",
    "        self.scale = scale\n",
    "        self.group_size = group_size\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        if mode == 'original':\n",
    "            self.num_units = len(self.scale)*self.group_size\n",
    "            self.index_li = {self.scale[i]: i for i in range(len(self.scale))}\n",
    "        elif mode == 'shift':\n",
    "            self.num_units = sum(self.scale)*self.group_size\n",
    "            self.index_li = {i:i-1 for i in self.scale}\n",
    "            \n",
    "        self.class_dim = 2\n",
    "        self.input_dim = input_dim\n",
    "        self.linear_h = nn.Linear(self.num_units,self.num_units)\n",
    "        self.linear_o = nn.Linear(self.num_units,self.class_dim)\n",
    "        self.linear_i = nn.Linear(self.input_dim, self.num_units)\n",
    "        self.activation_fun = activation_fun\n",
    "        self.connect = torch.from_numpy(block_tri(self.group_size, self.scale, self.num_units, self.mode)).float()\n",
    "        self.time_step = 0\n",
    "        print('----------------print connectivity-------------------------------------------------------')\n",
    "        print(self.connect)\n",
    "        \n",
    "        \n",
    "        self.initial_weights(mean, std)\n",
    "        \n",
    "        #the connectivity, when we disabled the weight, this should not change\n",
    "        self.linear_h.weight.data = self.linear_h.weight.data*self.connect#here needs transpose since previously left multiplication, activate mtrx doesn't need as rewrite and select cols.\n",
    "        #self.linear_i.weight.data = self.linear_i.weight.data\n",
    "        \n",
    "    def forward(self, sequence, hidden):#depends on what passed for model.train(), to be filled)\n",
    "        '''\n",
    "        sequence: batch  x timestep x number_feature matrix\n",
    "        hidden: should be h0\n",
    "        '''     \n",
    "        #sequence = sequence.view(48,-1)when this is only one batch\n",
    "        hidden_output = []\n",
    "        length = sequence.size()[1]\n",
    "        logit = []\n",
    "        for i in range(1,length+1):\n",
    "            print('this is the timestep ' + str(self.time_step))\n",
    "            self.time_step += 1\n",
    "            #backwards, want discharge/dead time aligns\n",
    "            #print(sequence[:,:,-i].size())#would be batch*48\n",
    "            hidden = self.CW_RNN_Cell(sequence[:,-i,:].contiguous(), hidden)\n",
    "            hidden_output.append(hidden)#become batch_size x hidden_dim\n",
    "            out = self.linear_o(hidden)\n",
    "            print('---------------- linear layer weight-------------------------------')\n",
    "            print(self.linear_o.weight.data)\n",
    "            print('---------------- out for prediction linear_o(hidden from next step)-------------------------------')\n",
    "            print(out[:,0] == out[:,1])#0 means false. test whether it cares about how many zeros are after this\n",
    "            #print(F.softmax(out))\n",
    "            print(hidden)\n",
    "            print(out)\n",
    "            print(F.log_softmax(out))\n",
    "            #print(out.size())#should be batch x 2 (for one timestep)\n",
    "            logit.append(F.log_softmax(out))\n",
    "        return hidden_output, logit\n",
    "            \n",
    "                \n",
    "    def CW_RNN_Cell(self, x_input, hidden):\n",
    "        '''\n",
    "        x_input: number_feature x batch vector, representing one time stamp\n",
    "        hidden: output of the last cell, should be hidden_dim(i.e. num_units) x batch\n",
    "        '''\n",
    "        print('---------------- hidden step -------------------------------------------------------')\n",
    "        print(hidden)\n",
    "\n",
    "        print('---------------- x_input -------------------------------------------------------')\n",
    "        print(x_input)\n",
    "        \n",
    "        #which time bloack to change\n",
    "        activate = activate_index(self.time_step, self.num_units, self.group_size, self.scale,self.index_li,batch_size,self.mode, self.input_dim)\n",
    "        activate_re = torch.from_numpy(np.ones((self.batch_size,self.num_units))).float() - activate\n",
    "        \n",
    "        #print('activate ' + str(activate.size()))\n",
    "        #print('activate_re ' + str(activate_re.size()))\n",
    "    \n",
    "        \n",
    "        print('----------------weight data for this step------------------------------------------------------')\n",
    "        #print(hidden)\n",
    "        print(self.linear_h.weight.data)\n",
    "        \n",
    "        print('----------------bias data for this step------------------------------------------------------')\n",
    "        #print(hidden)\n",
    "        print(self.linear_h.bias.data)        \n",
    "        \n",
    "        #print(self.linear_h.weight.data)\n",
    "        #*activate.transpose(0,1)\n",
    "        hidden_next = self.linear_h(hidden) + self.linear_i(x_input) #should be batch_size x hidden_dim\n",
    "        \n",
    "        print('----------------hidden_next data for this step------------------------------------------------------')\n",
    "        #print(hidden)\n",
    "        print(hidden_next) \n",
    "        \n",
    "        hidden_next.data = activate*hidden_next.data + activate_re*hidden.data\n",
    "        \n",
    "        print('----------------hidden_next data for this step------------------------------------------------------')\n",
    "        #print(hidden)\n",
    "        print(hidden_next) \n",
    "        \n",
    "        hidden_next = self.activation_fun(hidden_next)\n",
    "        return hidden_next\n",
    "\n",
    "    def init_hidden(self):\n",
    "        h0 = Variable(torch.zeros(self.batch_size,self.num_units))\n",
    "        return h0\n",
    "        \n",
    "    def initial_weights(self, mean, std):\n",
    "        lin_layers = [self.linear_h, self.linear_o, self.linear_i]\n",
    "        for layer in lin_layers:\n",
    "            layer.weight.data.normal_(mean, std**2)\n",
    "            layer.bias.data.fill_(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Training\n",
    "model = Clock_NN([1,2,4], batch_size, group_size = 5, activation_fun = F.relu, mean = 0, std = 0.1, input_dim = 5)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss(ignore_index=-1)  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "accuracy_list = []\n",
    "train_loader, validation_loader = reload_data(batch_size)\n",
    "for epoch in range(num_epochs):\n",
    "    for step, (data, label) in enumerate(train_loader):        \n",
    "        data, label = Variable(data), Variable(label)\n",
    "        model.zero_grad()\n",
    "        hidden= model.init_hidden()\n",
    "        hidden, output = model(data, hidden)\n",
    "        \n",
    "        #now get a list of hidden and a list of outputs\n",
    "        label = label.transpose(0,1).contiguous().view(-1) \n",
    "        #should be flatten, batch_size x hidden. transpose due to below order, was batch, seq => follow up 2 down. get size batch*seq\n",
    "        output = torch.stack(output, dim=1).view(-1, 2) \n",
    "        #since batch is the first dimension, so dim is 1. now the order is  seq_len,batch, 2, so the first dimension is the first time step over all batch\n",
    "        #print(output.size())\n",
    "        #print(label.size())\n",
    "        lossy = loss(output, label)\n",
    "        lossy.backward()\n",
    "        model.linear_h.weight.grad.data = model.linear_h.weight.grad.data*model.connect.transpose(0,1)\n",
    "        #print(lossy.data[0])\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
